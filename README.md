<h1 align="center">Your Models Have Thought Enough: Training Large Reasoning Models to Stop Overthinking</h1>


<div align="center"> 

[![Paper](https://img.shields.io/badge/Paper-arXiv-b5212f.svg?logo=arxiv)]()
[![HuggingFace](https://img.shields.io/badge/Data&Model-HuggingFace-ffd21e.svg?logo=huggingface)](https://huggingface.co/arm-team) 

</div>




# Requirements
This repository is based on VeRL and lighteval. We use two separate conda environments.
 
```bash
# JET Training 
conda env create -f environment/verl_env.yaml
conda activate verl_env

# Eval
conda env create -f environment/lighteval_env.yaml
conda activate lighteval_env
````

# Data
Training data: data/training/training_cleaned.json

Test data path: data/test

# QuickStart

```bash
# step1: JET Training 
conda activate verl_env
cd examples
bash run.sh

# step2: Merge the checkpoint
conda activate verl_env
python scripts/model_merger.py --local_dir your_ckp_path/global_step_70/actor

# step3: Eval
conda activate lighteval_env

````

<!-- # Models
We will release our models from [ðŸ¤—HuggingFace](https://huggingface.co/). -->